{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2. 임베딩 파일 로드 및 유사도 측정"
      ],
      "metadata": {
        "id": "S_EPpkecEglb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRhpQSq3D4AW",
        "outputId": "575a85ba-ffe8-4bae-d81b-9af4c6130ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=7c9591e5b4325cc6a97231e74df1e76d4ae6b3357d8f85fa52cb5e1a75a82186\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# SentenceTransformer 모델 로드\n",
        "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
        "\n",
        "# 엑셀 파일 읽기\n",
        "file_path = 'Question.xlsx'\n",
        "df = pd.read_excel('/content/Qusetion.xlsx')\n",
        "\n",
        "# '질문 (Query)','답변(Answer)' 열의 내용을 가져와서 임베딩 처리\n",
        "queries = df[['질문 (Query)','답변 (Answer)']].values.tolist()\n",
        "\n",
        "# 각 질문을 임베딩하여 리스트에 저장\n",
        "embeddings = model.encode(queries)\n",
        "\n",
        "# 임베딩된 결과를 새로운 열로 추가\n",
        "df['embedding_vector'] = embeddings.tolist()\n",
        "\n",
        "# 수정된 데이터프레임을 새로운 엑셀 파일로 저장\n",
        "output_file_path = 'Question_with_Embeddings_ST.xlsx'\n",
        "df.to_excel(output_file_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "M7v4r_ViD6zn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question= df['질문 (Query)']\n",
        "question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFr4rSSjFEWN",
        "outputId": "0ebb4676-4df3-4198-9f70-c8e411d763e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                강예인에게 어떻게 연락하면 될까?\n",
              "1                     강예인에게 연락하고 싶어\n",
              "2                      강예인의 번호를 알려줘\n",
              "3                    강예인의 전공을 알고 싶어\n",
              "4                      강예인의 전공이 뭐야?\n",
              "                   ...             \n",
              "321            수학과 복수전공 출신은 누가 있을까?\n",
              "322          수학과를 복수전공한 사람에는 누가 있어?\n",
              "323     데이터사이언스학과를 복수전공한 사람은 누가 있어?\n",
              "324      데이터사이언스학과 복수전공 출신은 누가 있을까?\n",
              "325    데이터사이언스학과를 복수전공한 사람에는 누가 있어?\n",
              "Name: 질문 (Query), Length: 326, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer=df['답변 (Answer)']\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dAu1U9OGmY7",
        "outputId": "fee21673-fbaa-4af6-dbc7-3117f9e242d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      전화번호 : 010-2397-9892, 이메일 : kangyein9892@gmail...\n",
              "1      전화번호 : 010-2397-9892, 이메일 : kangyein9892@gmail...\n",
              "2      전화번호 : 010-2397-9892, 이메일 : kangyein9892@gmail...\n",
              "3                                           제 1전공 : 정보보호\n",
              "4                                           제 1전공 : 정보보호\n",
              "                             ...                        \n",
              "321                                김수민님이 수학과를 복수전공했어요 :)\n",
              "322                                김수민님이 수학과를 복수전공했어요 :)\n",
              "323                          이서현님이 데이터사이언스학과를 복수전공했어요 :)\n",
              "324                          이서현님이 데이터사이언스학과를 복수전공했어요 :)\n",
              "325                          이서현님이 데이터사이언스학과를 복수전공했어요 :)\n",
              "Name: 답변 (Answer), Length: 326, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 질문열의 공백을 제거하는 코드\n",
        "df['질문 (Query)'] = df['질문 (Query)'].str.strip()\n",
        "\n",
        "#2.질문 문장 인코딩 후 텐서\n",
        "import torch\n",
        "# 질문 열('질문 (Query)')의 데이터를 가져옴\n",
        "sentences = df['질문 (Query)'].tolist()\n",
        "\n",
        "# 문장 인코딩\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "# 인코딩된 결과를 PyTorch 텐서로 변환\n",
        "tensor_embeddings = torch.tensor(sentence_embeddings)\n",
        "\n",
        "# 텐서 확인\n",
        "print(tensor_embeddings)\n",
        "\n",
        "# 3. 코사인 유사도 계산\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarities = cosine_similarity(sentence_embeddings, tensor_embeddings)\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lSIMibxItbl",
        "outputId": "60bdfae5-58cd-4ded-df92-3fe21f869caf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1004, -0.2406, -0.8142,  ..., -0.2475, -0.8355, -0.4555],\n",
            "        [ 0.2152, -0.3781, -1.4457,  ..., -0.1475, -0.3373, -0.7575],\n",
            "        [-0.1661, -0.2999, -0.3447,  ..., -0.7778, -0.4253, -0.0340],\n",
            "        ...,\n",
            "        [ 0.4802, -0.1664, -0.6722,  ...,  1.1298,  0.0243,  0.3059],\n",
            "        [ 0.4162, -0.0113, -0.6368,  ...,  1.3691,  0.1002, -0.1616],\n",
            "        [ 0.5886,  0.0427, -0.4040,  ...,  1.0908, -0.0666,  0.1542]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# 선택된 질문\n",
        "selected_question = \"AI부서에는 누가 있어?\"\n",
        "\n",
        "# 선택된 질문 출력\n",
        "print(f\"선택된 질문: {selected_question}\")\n",
        "\n",
        "\n",
        "# 선택된 질문 문장 인코딩\n",
        "selected_question_embedding = model.encode([selected_question])\n",
        "\n",
        "# 저장된 데이터셋의 질문 열의 임베딩 데이터 가져오기\n",
        "saved_embeddings = df['embedding_vector'].tolist()\n",
        "tensor_saved_embeddings = torch.tensor(saved_embeddings)\n",
        "\n",
        "# 선택된 질문과 저장된 데이터셋의 질문 간 코사인 유사도 계산\n",
        "similarities = cosine_similarity(selected_question_embedding, tensor_saved_embeddings)\n",
        "\n",
        "# 유사도가 가장 높은 질문의 인덱스 찾기\n",
        "most_similar_index = similarities.argmax()\n",
        "\n",
        "# 가장 높은 유사도를 가진 질문의 인덱스의 답변 출력\n",
        "selected_answer = df.loc[most_similar_index, '답변 (Answer)']\n",
        "print(f\"선택된 질문과 가장 유사한 질문의 답변: {selected_answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054GII8mI_Z1",
        "outputId": "910b31bc-a4db-4b62-a84f-4e5c56fbff79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 질문: AI부서에는 누가 있어?\n",
            "선택된 질문과 가장 유사한 질문의 답변: ai/ml 부서에 물어보시면 됩니다, ai/ml 부서에는 다음과 같은 사람들이 있습니다 (배지윤, 이재연, 정다혜, 김수민, 오윤선, 이서현)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUGLpYrJI_cO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}